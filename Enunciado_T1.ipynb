{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-393 Máquinas de Aprendizaje II-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 1  </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Problemas de clasificación y  regresión.\n",
    "* Selección de atributos y parámetros de regularización en regresión lineal (Ridge y Lasso).\n",
    "* Validación cruzada.\n",
    "* PCA e ICA versus LDA. Reducción de dimensionalidad para clasificación.\n",
    "* Selección de hı́per-parámetros estructurales en Regresión Logı́stica y Perceptrón.\n",
    "* LDA, QDA, Naive Bayes en texto, clasificadores bayesianos ingenuos (Bernoulli, Multinomial)\n",
    "* Preprocesamiento de datos brutos y representaciones de entrada.\n",
    " \n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y discusión: 26 de Octubre y 29 de Octubre respectivamente.\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea1-INF393-II-2018]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Aprendizaje con regresión lineal  \n",
    "[2.](#segundo) Análisis de audios como datos brutos  \n",
    "[3.](#tercero) Análisis de emociones en tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Aprendizaje con regresión lineal.\n",
    "\n",
    "El modelo de regresión lineal  es una combinación lineal entre variables independientes para obtener otra variable, dependiente de éstas. Lo cual puede resultar bastante simple, pero, hoy en día, ha podido ser aplicado a varios problemas con buenos resultados, como predicción en finanzas y en medicina. Sin embargo, también puede ser un medio para aplicar un modelo más grande, por ejemplo utilizarlo para que, con el resuido, detectar *outliers*, rellenar vacíos/datos incompletos o aprender un *score* para ranquear objetos, lo que haremos en esta sección.\n",
    "\n",
    "<img src=\"http://chanakya.ca/wp-content/uploads/2018/05/EstimateMultipleLinearRegressionCoefficientsExample_01.png\" height=\"15%\" />\n",
    "\n",
    "\n",
    "El problema de *learning to rank* es aplicado comúnmente en *Information Retrieval* (IR). Sin embargo, el aprender ésta función puede ser crucial para modelar la importancia de distintos objetos.  \n",
    "\n",
    "\n",
    "En esta actividad trabajaremos con el problema de predecir el *ranking* mundial de una Universidad en base a distintas características de ésta (dataset *World University Rankings*, a través del siguiente __[link](https://www.kaggle.com/mylesoneill/world-university-rankings)__) en la plataforma de *Kaggle*. En este problema el *ranking* es una medición de qué tan buena es la universidad e intentaremos predecirla a través un modelo simple de regresión lineal. En particular, dentro de los miles de diferentes sistemas de rankings, nacionales e internacionales, entre los cuales comúnmente existen desacuerdos entre ellos, trabajaremos con el ranking ampliamente considerado como uno de las más influyentes y ampliamente observadas: *Times Higher Education World University* .\n",
    "\n",
    "\n",
    "> a) Cargue los datos a analizar, descargándolos desde la plataforma como se indicó, en formato *dataframe pandas*. Descríbalos adecuadamente, ya sea la variable dependiente o las independientes, si es que lo son.\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"world-university-rankings/timesData.csv\")\n",
    "df.shape\n",
    "df.describe()\n",
    "```\n",
    "\n",
    "> b) Debido a la estructura será necesario realizar un leve pre-proceso. Existen vacíos entre los datos o valores '-', por lo que será necesario eliminarlos (*o si piensa una mejor manera de manejar ésto puede hacerlo, se verá reflejado en su nota*). Además de ésto deje los datos con *score unkown* o '-' en un conjunto *target* separado, *unlabeled data* (éste será el objetivo del entrenamiento) ¿Cuántos datos quedan en cada conjunto? \n",
    "```python\n",
    "def convertToInt(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        x = 0\n",
    "    return x\n",
    "df.dropna(axis=0,inplace=True,how='any') #borra nan\n",
    "df[\"total_score\"] = df3[\"total_score\"].apply(lambda x: x.replace('-','unknown')) #rellena \n",
    "df = df[~(df == '-').any(axis=1)] #elimina filas con valores nulos\n",
    "...\n",
    "nuevo_df  = pd.get_dummies(df, columns=[\"country\"]) #column to categorical\n",
    "....\n",
    "nuevo_df['female'] = nuevo_df['female_male_ratio'].str.split(':', expand=True)[0].apply(convertToInt)\n",
    "nuevo_df['male'] = nuevo_df['female_male_ratio'].str.split(':', expand=True)[1].apply(convertToInt)\n",
    "nuevo_df['female_male_ratio'] =  np.where(nuevo_df['male'] == 0, 0, nuevo_df['female']/nuevo_df['male']) #si no hay (rellena 0) \n",
    "nuevo_df['num_students'] = nuevo_df['num_students'].apply(lambda x: int(str(x).replace(',','')))\n",
    "nuevo_df['international_students'] = nuevo_df['international_students'].apply(lambda x: int(str(x).replace('%','')))\n",
    "print(nuevo_df.shape)\n",
    "...\n",
    "df_test = nuevo_df[nuevo_df[\"total_score\"]=='unknown']  #para predecir al final\n",
    "nuevo_df =  nuevo_df[nuevo_df[\"total_score\"]!='unknown'] #elimina unknown rank..\n",
    "print(nuevo_df.shape)\n",
    "nuevo_df.head()\n",
    "```\n",
    "\n",
    "> c) Cree las matrices de cada conjunto con las que trabajará. Además de ésto separe el conjunto de pruebas fijo que se utilizará, recuerde que éste no puede ser utilizado. Si estima conveniente también cree conjunto de validación.\n",
    "```python\n",
    "Y = nuevo_df['total_score'].values\n",
    "X = nuevo_df.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).values\n",
    "X_test = df_test.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).values\n",
    "Y = Y.astype('float32')\n",
    "X = X.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X.shape\n",
    "...\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "...\n",
    "validation_set = #if you want to create val!\n",
    "```\n",
    "\n",
    "> d) Normalice los datos antes de trabajar. Explique la importancia/conveniencia de realizar ésto.\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "> e) Realice una regresión lineal de mı́nimos cuadrados básica. Mida el residuo de cada predicción en cada dato y haga un gráfico de éste ¿Qué indica lo observado?\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "linreg = LR(fit_intercept=True, n_jobs=1)\n",
    "linreg.fit(X_train_scaled,y_train)\n",
    "...\n",
    "import seaborn as sns\n",
    "res = y_train-linreg.predict(X_train_scaled)\n",
    "sns.distplot(res)\n",
    "```\n",
    "\n",
    "> f) Construya una tabla con los pesos, Z-score y F-score correspondientes a cada predictor (variable), compare estos valores. ¿Qué sucede si hacemos un raking de los atributos en base al peso obtenido en la regresión? Compare y comente ¿Qué variables están más correlacionadas con la respuesta? Si usáramos un nivel de significación del 5%. ¿Qué es lo que observa y cuál puede ser la causa?\n",
    "\n",
    "> g) Calcule la información mútua de los distintos predictores (variables) con respecto a la variable *output* o *target*. Comente con lo calculado anteriormente y se le parece razonable.\n",
    "```python\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "minfo_predictor = mutual_info_regression(X,y)\n",
    "```\n",
    "\n",
    "> h)  Construya una función que implemente *Forward Step-wise Selection* (FSS). Es decir, partiendo con un modelo sin predictores (variables), agregue un predictor a la vez, re-ajustando el modelo de regresión en cada paso. Para seleccionar localmente una variable, proponga/implemente un criterio distinto al utilizado en el código de ejemplo. Construya un gráfico que muestre el error de entrenamiento y el error de pruebas como función del número de variables en el modelo. Ordene el eje $x$ de menor a mayor.\n",
    "```python\n",
    "def fss(x, y, names_x, k = 10000):\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = range(0, p)\n",
    "    selected = [p]\n",
    "    current_score = best_new_score = 0.0\n",
    "    while remaining and len(selected)<=k :\n",
    "        score_candidates = []\n",
    "        for candidate in remaining:\n",
    "            model = LR(fit_intercept=True, n_jobs=1)\n",
    "            indexes = selected + [candidate]\n",
    "            x_train = x[:,indexes]\n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            residuals_train = predictions_train - y\n",
    "            mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "            score_candidates.append((mse_candidate, candidate))\n",
    "        score_candidates.sort()\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        best_new_score, best_candidate = score_candidates.pop()\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        print \"selected = %s ...\"%names_x[best_candidate]\n",
    "        print \"totalvars=%d, mse = %f\"%(len(indexes),best_new_score)\n",
    "    return selected\n",
    "names_regressors = nuevo_df.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).columns\n",
    "fss(X_train_scaled,y_train,names_regressors)\n",
    "```\n",
    "\n",
    "> i) Ajuste un modelo lineal utilizando “*Ridge Regression*”, es decir, regularizando con la norma $l_2$. Utilice valores del parámetro de regularización $\\lambda$ en el rango [$10^0, 10^6$], variando si estima conveniente. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Deje un gráfico sólo para analizar los coeficientes de los países. Describa lo que observa.\n",
    "```python\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pylab as plt\n",
    "names_regressors = nuevo_df.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).columns\n",
    "alphas_ = np.logspace(0,6,base=10)\n",
    "coefs = []\n",
    "model = Ridge(fit_intercept=True,solver='svd')\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    coefs.append(model.coef_)\n",
    "ax = plt.gca()\n",
    "for y_arr, label in zip(np.squeeze(coefs).T, names_regressors):\n",
    "    if \"country\" not in label:\n",
    "        plt.plot(alphas_, y_arr, label=label)\n",
    "ax.set_xscale('log')\n",
    "plt.title('Regularization Path RIDGE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "...#modify\n",
    "if \"country\" in label:\n",
    "    plt.plot(alphas_, y_arr, label=label)\n",
    "plt.title('Regularization Path RIDGE of country coefs')\n",
    "```\n",
    "\n",
    "> j) Ajuste un modelo lineal utilizando el método “*Lasso*”, es decir, regularizando con la norma $l_1$. Utilice valores del parámetro de regularización $\\lambda$ en el rango [$10^{-2},10^3$]. Para obtener el código, modifique el ejemplo anterior. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Describa lo que observa. ¿Es más efectivo *Lasso* para seleccionar atributos?\n",
    "```python\n",
    "from sklearn.linear_model import Lasso\n",
    "alphas_ = np.logspace(-2,3,base=10)\n",
    "model = Lasso(fit_intercept=True)\n",
    "...\n",
    "country_alphas_ = np.logspace(-5,0,base=10)\n",
    "```\n",
    "> k) Escogiendo uno de los dos métodos regularizadores anteriores, especificando el porqué, construya un gráfico que muestre el error de entrenamiento y el de pruebas como función del parámetro de regularización. Discuta lo que  observa.\n",
    "```python\n",
    "alphas_ = #choose it\n",
    "coefs = []\n",
    "model = #choose it\n",
    "mse_test = []\n",
    "mse_train = []\n",
    "for a in alphas_:\n",
    "    model.set_params(alpha=a)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    yhat_train = model.predict(X_train_scaled)\n",
    "    yhat_test = model.predict(X_test_scaled)\n",
    "    mse_train.append(np.mean(np.power(yhat_train - y_train, 2)))\n",
    "    mse_test.append(np.mean(np.power(yhat_test - y_test, 2)))\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas_,mse_train,label='train error ridge/lasso')\n",
    "ax.plot(alphas_,mse_test,label='test error ridge/lasso')\n",
    "plt.legend(loc=1)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.get_xlim()[::-1])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "> l) Estime el valor del parámetro de regularización en **alguno** de los modelos anteriores haciendo uso de la técnica validación cruzada con un número de folds igual a $K= 5$ y $K = 10$. Recuerde que para que la estimación sea razonable, en cada configuración (*fold*) deberá reajustar los pesos del modelo. Mida el error real del modelo (ésto es sobre el conjunto de pruebas). Debido a la escala del error puede utilizar auxiliarmente *MAE* como métrica de desempeño. Compare y concluya.\n",
    "```python\n",
    "yhat_test = linreg.predict(X_test_scaled)\n",
    "mse_test = np.mean(np.power(yhat_test - y_test, 2))\n",
    "from sklearn.model_selection import KFold\n",
    "K=10\n",
    "kf = KFold(n_splits=K)\n",
    "mse_cv = 0\n",
    "for train, val in kf.split(X_train_scaled):\n",
    "    linreg = LR(fit_intercept=True, n_jobs=1)\n",
    "    linreg.fit(X_train_scaled[train], y_train[train])\n",
    "    yhat_kfold_val = linreg.predict(X_train_scaled[val])\n",
    "    mse_fold = np.mean(np.power(yhat_kfold_val - y_train[val], 2))\n",
    "    mse_cv += mse_fold\n",
    "mse_cv = mse_cv / K\n",
    "...#or MAE\n",
    "mae_fold = np.mean(np.abs(yhat_kfold_val - y_train[val]))\n",
    "```\n",
    "\n",
    "> m) Con el modelo que se piense que es el mejor, en base a todo lo experimentado. Realice el *ranking* de las universidades del que no se tienen etiquetas (*unlabeled data* o *target data*) a través de predecir los datos que se dejaron como *pruebas* y ordenar su score en el *dataframe*.\n",
    "```python\n",
    "df_test[\"total_score\"] = model.predict(X_test_scaled) #predict score\n",
    "...#armar un raking\n",
    "univ_chilenas = df_test[df_test[\"country_Chile\"]==1]\n",
    "rannking_univ_ch = univ_chilenas.sort_values(by=\"total_score\",ascending=False)\n",
    "ranking = 1\n",
    "for index,row in rannking_univ_ch.iterrows():\n",
    "    print(\"%d - Institucion: %s\" %(ranking,row[\"university_name\"]))\n",
    "    ranking+=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"segundo\"></a>\n",
    "## 2. Análisis de audios como datos brutos\n",
    "\n",
    "Distintos tipos de datos han sido tratados en el área de Machine Learning, donde el análisis de estos y\n",
    "el manejo para poder dejarlos en una representación que se pueda entregar como entrada al algoritmo es\n",
    "crucial. El manejo sobre los datos brutos se denomina pre-procesamiento y existen distintos dependiento del\n",
    "tipo de datos y los distintos diminios de problemas, tales como imágenes, audios, texto.  \n",
    "En esta actividad se trabajará con datos de audios los cuales son directamente extraı́dos desde datos fuentes\n",
    "*.wav*, lo que corresponde a una señal de sonido en diferentes tiempos.\n",
    "\n",
    "<img src=\"https://cdn.shopify.com/s/files/1/0977/4240/products/il_fullxfull.1054777221_nym4.jpg?v=1527718941\" width=\"40%\" />\n",
    "\n",
    "\n",
    "\n",
    "El *dataset* se denomina **Heartbeat Sounds**[[3]](#refs) y es presentado en la plataforma Kaggle a través del siguiente  __[link](https://www.kaggle.com/kinguistics/heartbeat-sounds)__. Este dataset consta de grabaciones de sonidos de latidos cardı́acos normales y anormales, con distintas categorı́as para los latidos anormales. Para la tarea se trabajará con el *dataset A* presente en la data, el cual corresponde a datos generados desde la vı́a pública mediante la aplicación de Iphone iStethoscope Pro. El objetivo será el de clasificar cada sonido como latido cardı́aco normal o una de las las subcategorı́as de anormal (*Murmur, Extra Heart Sound, Artifact*), por lo que se trata de un problema de clasificación múltiple con 4 clases. Las distintas clasificaciones para los sonidos son explicadas en el sitio de Kaggle.\n",
    "\n",
    "Para leer y trabajar los archivos de extensión *.wav* se utilizará el siguiente código:\n",
    "```python\n",
    "from scipy.io import wavfile\n",
    "def clean_filename(fname, string):\n",
    "    file_name = fname.split('/')[1]\n",
    "    if file_name[:2] == '__':\n",
    "        file_name = string + file_name\n",
    "    return file_name\n",
    "SAMPLE_RATE = 44100\n",
    "def load_wav_file(name, path):\n",
    "    s, b = wavfile.read(path + name)\n",
    "    assert s == SAMPLE_RATE\n",
    "    return b\n",
    "```\n",
    "\n",
    "> a) Construya un dataframe con los datos a analizar. Describa el dataset y determine cuántos registros hay\n",
    "por clase.\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./heartbeat-sounds/set_a.csv')\n",
    "```\n",
    "\n",
    "> b) Lea los archivos *.wav* y transformelos en secuencias de tiempo. Realice un *padding* de ceros al final de cada secuencia para que todas queden representadas con la misma cantidad de elementos, explique la importancia de realizar este paso.\n",
    "```python\n",
    "def padd_zeros(array,length):\n",
    "    aux = np.zeros(length)\n",
    "    aux[:array.shape[0]] = array\n",
    "    return aux\n",
    "new_df =pd.DataFrame({'file_name' : df['fname'].apply(clean_filename,string='Aunlabelled')})\n",
    "new_df['time_series'] = new_df['file_name'].apply(load_wav_file, path='path/to/set_a/')\n",
    "new_df['len_series'] = new_df['time_series'].apply(len)\n",
    "new_df['time_series']=new_df['time_series'].apply(padd_zeros,length=max(new_df['len_series']))\n",
    "```\n",
    "> c) Manipule los datos y cambie las etiquetas de los audios por otras asignadas por un doctor experto [[4]](#refs), el cual afirma que estos cambios son requeridos. Vuelva a determinar cuántos registros hay por clase. Nótese que ahora son 3 clases ¿Explique la problemática de tener etiquetas mal asignadas en los datos? ¿Un solo dato puede afectar esto?\n",
    "```python\n",
    "new_labels = ...\n",
    "labels = ['artifact','normal/extrahls', 'murmur']\n",
    "new_df['target'] = [labels[i] for i in new_labels]\n",
    "```\n",
    "\n",
    "> d) Codifique las distintas clases a valores numéricos para que puedan ser trabajados por los algoritmos\n",
    "clasificadores.\n",
    "```python\n",
    "new_df[\"target\"] = new_df[\"target\"].astype('category')\n",
    "cat_columns = new_df.select_dtypes(['category']).columns\n",
    "new_df[cat_columns] = new_df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "```\n",
    "\n",
    "> e) Desordene los datos, evitando ası́ el orden en el que vienen la gran mayorı́a de las etiquetas. Cree la matriz que conforma a los datos en sus dimensiones sin preprocesar, es decir, cada ejemplo es una secuencia de amplitudes en el tiempo. ¿Las dimensiones de ésta indica que puede generar problemas? ¿De qué tipo?\n",
    "```python\n",
    "new_df = new_df.sample(frac=1,random_state=44)\n",
    "X = np.stack(new_df['time_series'].values, axis=0)\n",
    "y = new_df.target.values\n",
    "X.shape\n",
    "```\n",
    "\n",
    "> f) Para pre-procesar la secuencia en el tiempo realice una transformada de fourier discreta [[5]](#refs) para pasar los datos desde el dominio de tiempos al dominio de frecuencias presentes en la señal de sonido. Visualice el cambio de representación.\n",
    "```python\n",
    "X_fourier = np.abs(np.fft.fft(X))\n",
    "```\n",
    "\n",
    "> g) Para seguir con el pre-procesamiento realice un muestreo representativo de los datos a través de una técnica de muestreo especializada en secuencias ¿En qué beneficia este paso? ¿Cómo podrı́a determinar si el muestro es representativo?\n",
    "```python\n",
    "from scipy import signal\n",
    "X_resampled = []\n",
    "for i in range(X_fourier.shape[0]):\n",
    "    sequence = X_fourier[i,:].copy()\n",
    "    resampled_sequence = signal.resample(sequence, 100000)\n",
    "    X_resampled.append(resampled_sequence)\n",
    "X_resampled = np.array(X_resampled)\n",
    "X_resampled.shape\n",
    "```\n",
    "\n",
    "> h) Debido a que no hay conjunto de pruebas, y que es necesario para evaluar la calidad **final** del modelo, genérelo a través de la técnica *hold-out*\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y, test_size=0.25, random_state=42)\n",
    "```\n",
    "\n",
    "> i) Realice un proceso de estándarizar los datos para ser trabajados adecuadamente. Recuerde que solo se debe ajustar (calcular media y desviación estándar) con el conjunto de entrenamiento.\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler(with_mean=True, with_std=True)\n",
    "std.fit(X_train)\n",
    "X_train = std.transform(X_train)\n",
    "X_test = std.transform(X_test)\n",
    "```\n",
    "> j) Realice una reducción de dimensionalidad a través de la técnica **PCA**, para representar los datos en $d = 2$ dimensiones. Recuerde que solo se debe ajustar (encontrar las componentes principales) con el conjunto de entrenamiento. Visualice apropiadamente la proyección en 2 dimensiones.\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "d=2\n",
    "pca_model = PCA(n_components=d)\n",
    "pca_model.fit(X_train)\n",
    "X_pca_train = pca_model.transform(X_train)\n",
    "X_pca_test = pca_model.transform(X_test)\n",
    "```\n",
    "\n",
    "> k) Entrene un modelo de Regresión Logı́stica variando el parámetro de regularización $C$ construyendo un gráfico resumen del error en función de este hiper-parámetro. Además entrene un Perceptrón, variando el hiper-parámetro de regularización $\\alpha$ en el rango inverso que para la Regresión Logı́stica ¿Por qué? Contruya el mismo gráfico resumen, en función de $C$ o $\\alpha$. Compare y comente lo observado.\n",
    "```python\n",
    "Cs = [0.0001,0.001,0.01,0.1,1,10,100,1000,10000]\n",
    "alphas = [1/c for c in Cs]\n",
    "from sklearn.linear_model import Perceptron,LogisticRegression\n",
    "model = LogisticRegression(penalty='l2', C=c,max_iter=200)\n",
    "model = Perceptron(penalty='l2', alpha=a, max_iter=200)\n",
    "```\n",
    "\n",
    "> l) Genere otra representación de los datos a través de la técnica de reducción de dimensionalidad **ICA**, con dimensionalidad $d = 2$. Recuerde que sólo se debe ajustar con el conjunto de entrenamiento, si se muestra un *warning* explique el porqué. Visualice apropiadamente la proyección en 2 dimensiones. Vuelva a realizar el item k) pero para esta nueva representación.\n",
    "```python\n",
    "from sklearn.decomposition import FastICA\n",
    "ica_model = FastICA(n_components=d)\n",
    "ica_model.fit(X_train)\n",
    "X_ica_train = ica_model.transform(X_train)\n",
    "X_ica_test = ica_model.transform(X_test)\n",
    "```\n",
    "\n",
    "> m) Experimente con diferentes dimensiones $d$ para la proyección de PCA e ICA con el propósito de obtener un modelo con menor error. Construya una tabla o gráfico resumen de los errores o *accuracy*, comente.\n",
    "\n",
    "> n) Realice otra reducción de dimensionalidad ahora a través de la técnica **LDA**, para representar los datos en $d = 2$ dimensiones. Recuerde que sólo se debe ajustar con el conjunto de entrenamiento, si se muestra un *warning* explique el porqué. Visualice apropiadamente la proyección en 2 dimensiones.\n",
    "```python\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda_model = LDA(n_components=2)\n",
    "lda_model.fit(X_train,y_train)\n",
    "X_lda_train = lda_model.transform(X_train)\n",
    "X_lda_test = lda_model.transform(X_test)\n",
    "```\n",
    "\n",
    "> o) Con el propósito de encontrar el mejor modelo vuelva a realizar el item k) en el nuevo espacio generado por la representación según las $d$ dimensiones de la proyección LDA. Esta nueva representación ¿mejora o empeora el desempeño? Explique.\n",
    "\n",
    "> p) Intente mejorar el desempeño de los algoritmos ya entrenados. Diseñe ahora sus propias cracterı́sticas (*feature crafting*) a partir de los datos brutos (secuencia de amplitudes), puede inspirarse en otros trabajos [[6]](#refs), [[7]](#refs)  si desea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tercero\"></a>\n",
    "## 3. Análisis de emociones en *tweets*\n",
    "\n",
    "El análisis de emociones o sentimientos se refiere al proceso de extraer información acerca de la actitud que una persona (o grupo de ellas) manifiesta, en un determinado medio o formato digital, con respecto a un tópico o contexto de comunicación. Uno de los casos más estudiados corresponde a determinar la polaridad de un trozo de texto, es decir, clasificar una determinada evaluación escrita (review ), en que una persona manifiesta una opinión, como positiva, negativa o neutral. Esto también ha sido extendido a otros medios, como lo es analizar la polaridad de textos en redes sociales.\n",
    "\n",
    "<img src=\"https://image.flaticon.com/sprites/new_packs/132222-color-emotions-assets.png\" width=\"40%\" />\n",
    "\n",
    "\n",
    "\n",
    "Para esta actividad se trabajará con un datasets de tweets ofrecidos por CrowdFlower[[8]](#refs). Cada *tweet* está\n",
    "asociado a una emoción en particular, donde el conjunto de emociones se trabajarán como mutuamente excluyentes, siendo un problema de múltiples clases.\n",
    "\n",
    "Los datos pueden ser descargados ejecutando el siguiente código en sistema Unix:\n",
    "```\n",
    "wget https://www.crowdflower.com/wp-content/uploads/2016/07/text_emotion.csv\n",
    "```\n",
    "\n",
    "Para aumentar la eficacia de las caracterı́sticas extraı́das es conveniente ejecutar algunas técnicas de pre-procesamiento básicas.\n",
    "\n",
    "> a) Construya un dataframe con los datos a analizar. Determine cuántas clases existen, cuántos registros por clase y describa el dataset.\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./emotionanalysis/text_emotion.csv')\n",
    "```\n",
    "\n",
    "> b) Construya un conjunto de entrenamiento y otro de pruebas, a través de una máscara aleatoria, para verificar los resultados de los algoritmos. Genere un conjunto de validación si estima conveniente.\n",
    "```python\n",
    "import numpy as np\n",
    "np.seed(70)\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "```\n",
    "\n",
    "> c) Construya las representaciones de los datos con los que trabajará, ya sea para las entradas de los modelos como para las salidas. Recuerde que tendrá que codificar las distintas clases como valores numéricos enteros. \n",
    "\n",
    "> d) Entrene y compare al menos 4 de los diferentes clasificadores vistos en clases para clasificación (por ejemplo: Navie Bayes, Multinomial Naive Bayes, LDA, QDA, Regresión logı́stica y Perceptrón). Recuerde que algunos son extendidos por defecto a múltiples clases para detectar emociones en cada *tweet*, sin embargo, otros deben ser extentidos a través de otras técnicas, tal como *One vs One* y *One vs All/Rest*. Muestre tabla o gráfico resumen.\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "#example\n",
    "classif = OneVsRestClassifier(model)\n",
    "classif.fit(X, Y)\n",
    "#or for LR\n",
    "LogisticRegression(multi_class= 'ovr' or 'multinomial')\n",
    "```\n",
    "\n",
    "> e) Utilice la técnica de ECOC (*Error-Correcting Output-Code*) para extender a multiclases algunos de los clasificadores utilizados en d). Comente lo que hace la técnica y los resultados observados.\n",
    "\n",
    "\n",
    "> f) Evalúe la métrica de *accuracy* sobre el conjunto de pruebas del mejor clasificador encontrado.  \n",
    "*Recuerde que puede acudir a otras métricas para tener otras visiones de lo que está haciendo el modelo de aprendizaje*\n",
    "\n",
    "> g) Intente mejorar su resultado considerablemente a través de alguna mejora novedosa. Se espera que supere el 35% de *accuracy*.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\"> Una opción es cambiar considerablemente la representación de los textos, ya sea con Tf-Idf, word2vec[[9]](#refs) , doc2vec[[10]](#refs) , otros. </div>\n",
    "\n",
    "<div class=\"alert alert-warning\"> Otra opción es hacer una clasificación por grupos, es decir, agrupar emociones para ir distinguiendo y bajar la granulidad de la clasificación. Como una clasificación jerárquica en modo árbol.</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refs\"></a>\n",
    "## Referencias\n",
    "[1] Hastie, T.; Tibshirani, R., Friedman, J. (2009), *The Elements of Statistical Learning*, Second Edition.\n",
    "Springer New York Inc.  \n",
    "[2] Ethem Alpaydin. *Machine Learning*. 2014.  \n",
    "[3] Bentley, P. and Nordehn, G. and Coimbra, M. and Mannor (2011) , Classifying Heart Sounds Challenge,\n",
    "CHSC2011, http://www.peterjbentley.com/heartchallenge/index.html  \n",
    "[4] https://www.kaggle.com/toregil/new-labels-for-set-a  \n",
    "[5] https://en.wikipedia.org/wiki/Fourier transform  \n",
    "[6] https://www.kaggle.com/primaryobjects/voicegender/data  \n",
    "[7] Gamit, M. R., Dhameliya, P. K., & Bhatt, N. S. (2015). Classification Techniques for Speech Recognition:\n",
    "A Review. vol, 5, 58-63.  \n",
    "[8] www.figure-eight.com/  \n",
    "[9] https://machinelearningmastery.com/develop-word-embeddings-python-gensim/, https://radimrehurek.com/gensim/models/word2vec.html or https://nathanrooy.github.io/posts/2018-03-22/word2vec-from-scratch-with-python-and-numpy/  \n",
    "[10] https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-6-doc2vec-603f11832504"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
